#!/usr/bin/env python

import os
from os.path import dirname
from os.path import join
import time

master_ip = "10.54.1.36"
data_path = "/users/wdai/datasets/lr/synth/lr2sp_dim500_s5000_nnz200x1.libsvm.0"
driver_memory = "4g"

params = {
    "numIterations": 10
    , "stepSize": 1e-7
    , "regType": "NONE"  # Options: L1, L2, NONE
    , "regParam": 0
    , "dataFormat", "LibSVM"
    , "miniBatchFraction": 1
    , "numLegs": 1
    , "numDups": 1
    }

script_dir = dirname(os.path.realpath(__file__))
spark_dir = "/home/wdai/spark-1.3.1"

cmd = "time %s/bin/spark-submit" % spark_dir
cmd += " --class LogisticRegression"
cmd += " --master spark://%s:7077" % master_ip
cmd += " --driver-memory " + driver_memory
cmd += " %s/lr/target/lr-1.0.jar" % script_dir
cmd += "".join([" -%s %s" % (k,v) for k,v in params.items()])
cmd += " " + data_path

print cmd
os.system(cmd)
